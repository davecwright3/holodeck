{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from holodeck import plot, detstats, utils\n",
    "from holodeck.constants import YR, MSOL, MPC, GYR\n",
    "import holodeck as holo\n",
    "\n",
    "import hasasia.sensitivity as hsen\n",
    "import hasasia.sim as hsim\n",
    "import hasasia.skymap as hsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = None\n",
    "NREALS = 500\n",
    "NFREQS = 40\n",
    "NLOUDEST = 10\n",
    "\n",
    "SAVEFIG = False\n",
    "TOL=0.01\n",
    "MAXBADS=5\n",
    "\n",
    "RED_GAMMA = None\n",
    "RED2WHITE = None\n",
    "\n",
    "NVARS = 21\n",
    "\n",
    "NPSRS = 40\n",
    "NSKIES = 100\n",
    "TARGET = 'gsmf_phi0' # EDIT AS NEEDED\n",
    "TITLE = plot.PARAM_KEYS[TARGET]  # EDIT AS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(\n",
    "        target, nvars=NVARS, nreals=NREALS, nskies=NSKIES, shape=SHAPE, red_gamma = None, red2white=None,\n",
    "    path = '/Users/emigardiner/GWs/holodeck/output/anatomy_redz',     \n",
    "):\n",
    "    load_data_from_file = path+f'/{target}_v{nvars}_r{nreals}_shape{str(shape)}/data_params.npz' \n",
    "\n",
    "    if os.path.exists(load_data_from_file) is False:\n",
    "        err = f\"load data file '{load_data_from_file}' does not exist, you need to construct it.\"\n",
    "        raise Exception(err)\n",
    "    file = np.load(load_data_from_file, allow_pickle=True)\n",
    "    data = file['data']\n",
    "    params = file['params']\n",
    "    file.close()\n",
    "    print(target, \"got data\")\n",
    "\n",
    "    return data, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, params = get_data(TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=10\n",
    "\n",
    "fobs_cents = data[var]['fobs_cents']\n",
    "dur = 1.0 / fobs_cents[0]\n",
    "cad = 1.0 / (2.0 * fobs_cents[-1])\n",
    "hc_ss = data[var]['hc_ss']\n",
    "hc_bg = data[var]['hc_bg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phis = None\n",
    "thetas = None\n",
    "npsrs = NPSRS\n",
    "red2white = RED2WHITE\n",
    "sigstart = 1.5e-7\n",
    "\n",
    "# randomize pulsar positions\n",
    "if phis is None: phis = np.random.uniform(0, 2*np.pi, size = npsrs)\n",
    "if thetas is None: thetas = np.random.uniform(np.pi/2, np.pi/2, size = npsrs)\n",
    "sigma = sigstart\n",
    "# if red2white is not None:\n",
    "#     red_amp = _white_noise(cad, sigma) * red2white\n",
    "\n",
    "psrs = hsim.sim_pta(timespan=dur/YR, cad=1/(cad/YR), sigma=sigma,\n",
    "                phi=phis, theta=thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_bg = detstats.detect_bg_pta(psrs, fobs_cents, hc_bg=hc_bg[:,np.newaxis], hc_ss=hc_ss[:,np.newaxis,:],\n",
    "                            red_amp=None, red_gamma=None, ss_noise=False)[0]\n",
    "print(holo.utils.stats(dp_bg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = []\n",
    "for psr in psrs:\n",
    "    sp = hsen.Spectrum(psr, freqs=fobs_cents)\n",
    "    sp.NcalInv\n",
    "    spectra.append(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_ss = hsen.DeterSensitivityCurve(spectra).h_c\n",
    "sc_bg = hsen.GWBSensitivityCurve(spectra).h_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax(xlabel=plot.LABEL_GW_FREQUENCY_YR, ylabel=plot.LABEL_CHARACTERISTIC_STRAIN)\n",
    "xx = fobs_cents*YR\n",
    "ax.plot(xx, sc_bg, label='BG Sensitivity', linestyle='--', color='tab:blue')\n",
    "ax.plot(xx, sc_ss, label='SS Sensitivity', linestyle='--', color='tab:pink')\n",
    "\n",
    "ax.fill_between(xx, *np.percentile(hc_bg, (25,75), axis=-1), \n",
    "                color='tab:blue', alpha=0.2)\n",
    "ax.plot(xx, np.median(hc_bg, axis=-1), label='hc_BG', color='tab:blue')\n",
    "\n",
    "ax.fill_between(xx, *np.percentile(hc_ss[:,:,0], (25, 75), axis=-1),\n",
    "                color='tab:pink', alpha=0.2)\n",
    "ax.plot(xx, np.median(hc_ss[:,:,0], axis=-1), label='hc_SS', color='tab:pink')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate detstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathrm{noise} = \\frac{h_{c,sens}^2}{ 12\\pi^2 f^3 }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sc_ss.shape)\n",
    "noise_has_ss = sc_ss**2 / fobs_cents**3 / (12*np.pi**2)\n",
    "noise_ss = np.repeat(noise_has_ss, NPSRS*NREALS*NLOUDEST).reshape(NFREQS, NPSRS, NREALS, NLOUDEST) # (F,P,R,L)\n",
    "noise_ss = np.swapaxes(noise_ss, 0, 1) # (P,F,R,L)\n",
    "\n",
    "Sh_rest = detstats._Sh_rest_noise(hc_ss, hc_bg, fobs_cents) # (F,R,L)\n",
    "noise_ss = noise_ss + Sh_rest[np.newaxis,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_ss_has, snr_ss_has, dp_ssi_has = detstats.detect_ss_pta(\n",
    "    psrs, fobs_cents, hc_ss, hc_bg, nskies=NSKIES,\n",
    "    custom_noise=noise_ss, ret_snr=True)\n",
    "dp_ss_def, snr_ss_def, dp_ssi_def = detstats.detect_ss_pta(\n",
    "    psrs, fobs_cents, hc_ss, hc_bg, nskies=NSKIES,\n",
    "    custom_noise=None, ret_snr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.repeat(fobs_cents, NREALS*NSKIES*NLOUDEST).reshape(NFREQS, NREALS, NSKIES, NLOUDEST)*YR\n",
    "favg_has, var2_has = detstats.weighted_mean_variance(freqs, dp_ssi_has)\n",
    "favg_def, var2_def = detstats.weighted_mean_variance(freqs, dp_ssi_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax(\n",
    "    xlabel=plot.LABEL_GW_FREQUENCY_YR, ylabel='0th Loudest Detection Probability')\n",
    "xx = fobs_cents*YR\n",
    "\n",
    "y1 = dp_ssi_has[:,:,:,0].reshape(NFREQS, NREALS*NSKIES)\n",
    "label1 = 'noise = DeterSC + S_rest'\n",
    "y2 = dp_ssi_def[:,:,:,0].reshape(NFREQS, NREALS*NSKIES)\n",
    "label2 = 'noise = S_WN + S_rest'\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange',]\n",
    "handles = []\n",
    "\n",
    "for ii,yy  in enumerate([y1, y2]):\n",
    "    hh = plot.draw_med_conf_color(ax, xx, yy, color=colors[ii])\n",
    "    handles.append(hh)\n",
    "\n",
    "\n",
    "var2s = [var2_has, var2_def]\n",
    "colors = ['blue', 'orangered',]\n",
    "for ii,favg in enumerate([favg_has, favg_def]):\n",
    "    std = np.sqrt(var2s[ii])\n",
    "    hh = ax.axvline(favg, color=colors[ii], linestyle='--')\n",
    "    handles.append(hh)\n",
    "    # ax.axvspan(favg-std, favg+std, alpha=0.2, color=colors[ii])\n",
    "\n",
    "labels = [label1, label2, 'favg (DSC)', 'favg (WN)']\n",
    "ax.legend(handles=handles, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax(\n",
    "    xlabel=plot.LABEL_GW_FREQUENCY_YR, ylabel='Top 3 Detection Probability')\n",
    "xx = fobs_cents*YR\n",
    "\n",
    "y1 = dp_ssi_has[:,:,:,:3].reshape(NFREQS, NREALS*3*NSKIES)\n",
    "label1 = 'noise = has.sc + rest'\n",
    "y2 = dp_ssi_def[:,:,:,:3].reshape(NFREQS, NREALS*3*NSKIES)\n",
    "label2 = 'noise = white + rest'\n",
    "\n",
    "handles = []\n",
    "for yy  in [y1, y2]:\n",
    "    hh = plot.draw_med_conf(ax, xx, yy,)\n",
    "    handles.append(hh)\n",
    "\n",
    "ax.legend(handles=handles, labels=[label1, label2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax(\n",
    "    xlabel=plot.LABEL_GW_FREQUENCY_YR, ylabel='0th Loudest SNR')\n",
    "xx = fobs_cents*YR\n",
    "\n",
    "y1 = snr_ss_has[:,:,:,0].reshape(NFREQS, NREALS*NSKIES)\n",
    "label1 = 'noise = has.sc + rest'\n",
    "y2 = snr_ss_def[:,:,:,0].reshape(NFREQS, NREALS*NSKIES)\n",
    "label2 = 'noise = white + rest'\n",
    "\n",
    "handles = []\n",
    "for yy  in [y1, y2]:\n",
    "    hh = plot.draw_med_conf(ax, xx, yy,)\n",
    "    handles.append(hh)\n",
    "\n",
    "ax.legend(handles=handles, labels=[label1, label2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_noise_ss = detstats._total_noise(cad, np.repeat(sigma, NPSRS), hc_ss, hc_bg, fobs_cents)\n",
    "print(total_noise_ss.shape)\n",
    "\n",
    "white_noise = detstats._white_noise(cad, np.repeat(sigma, NPSRS))\n",
    "print(white_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax(xlabel=plot.LABEL_GW_FREQUENCY_YR, ylabel='noise')\n",
    "xx = fobs_cents*YR\n",
    "\n",
    "y1 = np.swapaxes(noise_ss[:,:,:,0], 0,1).reshape(NFREQS, NPSRS*NREALS)\n",
    "label1 = 'noise = has.sc + hc_rest'\n",
    "y2 = np.swapaxes(total_noise_ss[:,:,:,0], 0,1).reshape(NFREQS, NPSRS*NREALS)\n",
    "label2 = 'noise = white + hc_rest'\n",
    "y3 = white_noise[:,np.newaxis]\n",
    "label3 = 'white'\n",
    "y4 = (detstats._Sh_rest_noise(hc_ss, hc_bg, fobs_cents))[:,:,0]\n",
    "label4 = 'hc_rest'\n",
    "y5 = noise_has_ss[:,np.newaxis]\n",
    "label5 = 'has sens curve'\n",
    "print(y3.shape, y4.shape)\n",
    "\n",
    "handles = []\n",
    "colors = ['tab:blue', 'tab:orange', 'blue', 'green', 'orangered']\n",
    "linestyles = ['-', '-', '--', ':', ':']\n",
    "for ii,yy  in enumerate([y1, y2, y3, y4, y5]):\n",
    "    hh = ax.plot(xx, np.median(yy, axis=-1), color=colors[ii], linestyle=linestyles[ii])\n",
    "    ax.fill_between(xx, *np.percentile(yy, (5, 95), axis=-1), color=colors[ii], alpha=0.25)\n",
    "    # hh = plot.draw_med_conf_color(ax, xx, yy, color=colors[ii])\n",
    "    handles.append(hh)\n",
    "labels = [label1, label2, label3, label4, label5]\n",
    "ax.legend(handles=handles, labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate by Realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pspace_model_clbrt_pta(fobs_cents, hc_ss, hc_bg, npsrs, nskies, DSC=False,\n",
    "                        sigstart=1e-6, sigmin=1e-9, sigmax=1e-4, tol=0.01, maxbads=5,\n",
    "                        thresh=detstats.DEF_THRESH, debug=False, save_snr_ss=False, save_gamma_ssi=True,\n",
    "                        red_amp=None, red_gamma=None, red2white=None, ss_noise=False): \n",
    "    \"\"\" Detect pspace model using individual sigma calibration for each realization\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    red2white : scalar or None\n",
    "        Fixed ratio between red and white noise amplitude, if not None. \n",
    "        Otherwise, red noise stays fixed\n",
    "\n",
    "    \"\"\"\n",
    "    dur = 1.0/fobs_cents[0]\n",
    "    cad = 1.0/(2*fobs_cents[-1])\n",
    "\n",
    "    nfreqs, nreals, nloudest = [*hc_ss.shape]\n",
    "        \n",
    "    # form arrays for individual realization detstats\n",
    "    # set all to nan, only to be replaced if successful pta is found\n",
    "    dp_ss = np.ones((nreals, nskies)) * np.nan   \n",
    "    dp_bg = np.ones(nreals) * np.nan\n",
    "    snr_ss = np.ones((nfreqs, nreals, nskies, nloudest)) * np.nan\n",
    "    snr_bg = np.ones((nreals)) * np.nan\n",
    "    gamma_ssi = np.ones((nfreqs, nreals, nskies, nloudest)) * np.nan\n",
    "\n",
    "\n",
    "    # for each realization, \n",
    "    # use sigmin and sigmax from previous realization, \n",
    "    # unless it's the first realization of the sample\n",
    "    _sigstart, _sigmin, _sigmax = sigstart, sigmin, sigmax \n",
    "    if debug: \n",
    "        mod_start = datetime.now()\n",
    "        real_dur = datetime.now()\n",
    "    failed_psrs=0\n",
    "    for rr in range(nreals):\n",
    "        if debug: \n",
    "            now = datetime.now()\n",
    "            if (rr%100==99):\n",
    "                print(f\"{rr=}, {(now-real_dur)/100} s per realization, {_sigmin=:.2e}, {_sigmax=:.2e}, {_sigstart=:.2e}\")\n",
    "                real_dur = now\n",
    "\n",
    "        # get calibrated psrs \n",
    "        psrs, red_amp, _sigstart, _sigmin, _sigmax = detstats.calibrate_one_pta(hc_bg[:,rr], hc_ss[:,rr,:], fobs_cents, npsrs, tol=tol, maxbads=maxbads,\n",
    "                                    sigstart=_sigstart, sigmin=_sigmin, sigmax=_sigmax, debug=debug, ret_sig=True,\n",
    "                                    red_amp=red_amp, red_gamma=red_gamma, red2white=red2white, ss_noise=ss_noise)\n",
    "        _sigmin /= 2\n",
    "        _sigmax *= 2 + 2e-20 # >1e-20 to make sure it doesnt immediately fail the 0 check \n",
    "\n",
    "        if psrs is None:\n",
    "            failed_psrs += 1\n",
    "            continue # leave values as nan, if no successful PTA was found\n",
    "        \n",
    "        # use those psrs to calculate realization BG detstats\n",
    "        _dp_bg, _snr_bg = detstats.detect_bg_pta(psrs, fobs_cents, hc_bg[:,rr:rr+1],  hc_ss[:,rr:rr+1,:], ret_snr=True, red_amp=red_amp, red_gamma=red_gamma)\n",
    "        \n",
    "        dp_bg[rr], snr_bg[rr] = _dp_bg.squeeze(), _snr_bg.squeeze()\n",
    "\n",
    "\n",
    "        # calculate SS noise from DeterSensitivityCurve and S_h,rest\n",
    "        if DSC:\n",
    "            spectra = []\n",
    "            for psr in psrs:\n",
    "                sp = hsen.Spectrum(psr, freqs=fobs_cents)\n",
    "                sp.NcalInv\n",
    "                spectra.append(sp)\n",
    "            sc_hc = hsen.DeterSensitivityCurve(spectra).h_c\n",
    "            noise_dsc = sc_hc**2 / (12 * np.pi**2 * fobs_cents**3)\n",
    "            noise_dsc = np.repeat(noise_dsc, npsrs*1*nloudest).reshape(nfreqs, npsrs, 1, nloudest) # (F,P,R,L)\n",
    "            noise_dsc = np.swapaxes(noise_dsc, 0, 1)  # (P,F,R,L)\n",
    "            noise_rest = detstats._Sh_rest_noise(hc_ss[:,rr:rr+1,:], hc_bg[:,rr:rr+1], fobs_cents) # (F,R,L)\n",
    "            noise_ss = noise_dsc + noise_rest[np.newaxis,:,:,:]\n",
    "            \n",
    "        else:\n",
    "            noise_ss = None\n",
    "\n",
    "        # calculate realizatoin SS detstats\n",
    "        _dp_ss, _snr_ss, _gamma_ssi = detstats.detect_ss_pta(\n",
    "            psrs, fobs_cents, hc_ss[:,rr:rr+1], hc_bg[:,rr:rr+1], custom_noise=noise_ss,\n",
    "            nskies=nskies, ret_snr=True, red_amp=red_amp, red_gamma=red_gamma)\n",
    "        # if debug: print(f\"{_dp_ss.shape=}, {_snr_ss.shape=}, {_gamma_ssi.shape=}\")\n",
    "        dp_ss[rr], snr_ss[:,rr], gamma_ssi[:,rr] = _dp_ss.squeeze(), _snr_ss.squeeze(), _gamma_ssi.squeeze()\n",
    "\n",
    "    ev_ss = detstats.expval_of_ss(gamma_ssi)\n",
    "    df_ss, df_bg = detstats.detfrac_of_reals(dp_ss, dp_bg)\n",
    "    _dsdat = {\n",
    "        'dp_ss':dp_ss, 'snr_ss':snr_ss, 'gamma_ssi':gamma_ssi, \n",
    "        'dp_bg':dp_bg, 'snr_bg':snr_bg,\n",
    "        'df_ss':df_ss, 'df_bg':df_bg, 'ev_ss':ev_ss,\n",
    "        }\n",
    "    if save_gamma_ssi:\n",
    "        _dsdat.update(gamma_ssi=gamma_ssi)\n",
    "    if save_snr_ss:\n",
    "        _dsdat.update(snr_ss=snr_ss)\n",
    "    print(f\"Model took {datetime.now() - mod_start} s, {failed_psrs}/{nreals} realizations failed.\")\n",
    "    return _dsdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate calibrated DSC detstats\n",
    "\n",
    "_dsdat_has = detect_pspace_model_clbrt_pta(fobs_cents, hc_ss, hc_bg, NPSRS, NSKIES, DSC=True, \n",
    "                                       save_snr_ss=True, save_gamma_ssi=True, debug=True)\n",
    "dp_ss_clbrt_has = _dsdat_has['dp_ss']\n",
    "snr_ss_clbrt_has = _dsdat_has['snr_ss']\n",
    "dp_ssi_clbrt_has = _dsdat_has['gamma_ssi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate calibrated default (Rosado) detstats\n",
    "_dsdat_def = detect_pspace_model_clbrt_pta(fobs_cents, hc_ss, hc_bg, NPSRS, NSKIES, DSC=False, \n",
    "                                       save_snr_ss=True, save_gamma_ssi=True, debug=True)\n",
    "dp_ss_clbrt_def = _dsdat_def['dp_ss']\n",
    "snr_ss_clbrt_def = _dsdat_def['snr_ss']\n",
    "dp_ssi_clbrt_def = _dsdat_def['gamma_ssi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.repeat(fobs_cents, NREALS*NSKIES*NLOUDEST).reshape(NFREQS, NREALS, NSKIES, NLOUDEST)*YR\n",
    "favg_clbrt_has, var2_clbrt_has = detstats.weighted_mean_variance(freqs, dp_ssi_clbrt_has)\n",
    "favg_clbrt_def, var2_clbrt_def = detstats.weighted_mean_variance(freqs, dp_ssi_clbrt_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot.figax(\n",
    "    xlabel=plot.LABEL_GW_FREQUENCY_YR, ylabel='0th Loudest Detection Probability (Clbrtd)')\n",
    "xx = fobs_cents*YR\n",
    "\n",
    "y1 = dp_ssi_clbrt_has[:,:,:,0].reshape(NFREQS, NREALS*NSKIES)\n",
    "label1 = 'noise = DeterSC + S_rest'\n",
    "y2 = dp_ssi_clbrt_def[:,:,:,0].reshape(NFREQS, NREALS*NSKIES)\n",
    "label2 = 'noise = S_WN + S_rest'\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange',]\n",
    "handles = []\n",
    "\n",
    "for ii,yy  in enumerate([y1, y2]):\n",
    "    hh = plot.draw_med_conf_color(ax, xx, yy, color=colors[ii])\n",
    "    handles.append(hh)\n",
    "\n",
    "\n",
    "var2s = [var2_clbrt_has, var2_clbrt_def]\n",
    "colors = ['blue', 'orangered',]\n",
    "for ii,favg in enumerate([favg_clbrt_has, favg_clbrt_def]):\n",
    "    std = np.sqrt(var2s[ii])\n",
    "    hh = ax.axvline(favg, color=colors[ii], linestyle='--')\n",
    "    handles.append(hh)\n",
    "    # ax.axvspan(favg-std, favg+std, alpha=0.2, color=colors[ii])\n",
    "\n",
    "labels = [label1, label2, 'favg (DSC)', 'favg (WN)']\n",
    "ax.legend(handles=handles, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
